input {
  file {
    path => "/usr/share/logstash/input_files/logs_capteurs.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "capteurs"
    codec => plain { charset => "UTF-8" }
  }
}

filter {
  # Skip Redis messages (they have their own pipeline)
  if "from_redis" in [tags] {
    drop { }
  }
  
  if [type] != "capteurs" {
    drop { }
  }
  
  # Parse CSV
  csv {
    separator => ","
    columns => ["timestamp","capteur_id","type","valeur","unite","batiment","salle","etage","zone","statut_capteur","batterie","precision","derniere_calibration","seuil_min","seuil_max"]
    skip_header => true
  }

  # Trim whitespace
  mutate {
    strip => ["timestamp","capteur_id","type","valeur","unite","batiment","salle","etage","zone","statut_capteur","batterie","precision","derniere_calibration","seuil_min","seuil_max"]
  }

  # Convert numeric fields
  if [valeur] and [valeur] != "NA" {
    mutate { convert => { "valeur" => "float" } }
  }
  if [batterie] {
    mutate { convert => { "batterie" => "integer" } }
  }
  if [etage] {
    mutate { convert => { "etage" => "integer" } }
  }
  if [precision] and [precision] != "NA" {
    mutate { convert => { "precision" => "float" } }
  }
  if [seuil_min] {
    mutate { convert => { "seuil_min" => "float" } }
  }
  if [seuil_max] {
    mutate { convert => { "seuil_max" => "float" } }
  }

  # Parse timestamp
  if [timestamp] {
    date {
      match => [ "timestamp", "YYYY-MM-dd HH:mm:ss" ]
      target => "@timestamp"
      timezone => "UTC"
    }
  }

  # Remove unwanted fields
  mutate {
    remove_field => ["host", "log", "message", "event"]
  }
}

output {
  stdout { codec => rubydebug }
  
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "iot-capteurs"
  }
}
