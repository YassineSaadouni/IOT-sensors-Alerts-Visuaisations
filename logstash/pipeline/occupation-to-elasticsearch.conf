input {
  file {
    path => "/usr/share/logstash/input_files/logs_occupation.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "occupation"
    codec => plain { charset => "UTF-8" }
  }
}

filter {
  if [type] != "occupation" {
    drop { }
  }
  
  # Parse CSV
  csv {
    separator => ","
    columns => ["timestamp","salle_id","batiment","type_salle","capacite_max","nombre_personnes","taux_utilisation","evenement","organisateur","duree_prevue","equipements_utilises","temperature_moyenne","co2_moyen","consommation_elec","statut_occupation","zone","etage"]
    skip_header => true
  }

  # Trim whitespace
  mutate {
    strip => ["timestamp","salle_id","batiment","type_salle","capacite_max","nombre_personnes","taux_utilisation","evenement","organisateur","duree_prevue","equipements_utilises","temperature_moyenne","co2_moyen","consommation_elec","statut_occupation","zone","etage"]
  }

  # Convert numeric fields
  if [capacite_max] {
    mutate { convert => { "capacite_max" => "integer" } }
  }
  if [nombre_personnes] {
    mutate { convert => { "nombre_personnes" => "integer" } }
  }
  if [temperature_moyenne] {
    mutate { convert => { "temperature_moyenne" => "float" } }
  }
  if [co2_moyen] {
    mutate { convert => { "co2_moyen" => "integer" } }
  }
  if [consommation_elec] {
    mutate { convert => { "consommation_elec" => "float" } }
  }
  if [etage] {
    mutate { convert => { "etage" => "integer" } }
  }

  # Parse timestamp
  if [timestamp] {
    date {
      match => [ "timestamp", "YYYY-MM-dd HH:mm:ss" ]
      target => "@timestamp"
      timezone => "UTC"
    }
  }

  # Remove unwanted fields
  mutate {
    remove_field => ["host", "log", "message", "event"]
  }
}

output {
  stdout { codec => rubydebug }
  
  elasticsearch {
    hosts => ["http://elasticsearch:9200"]
    index => "iot-occupation"
  }
}
